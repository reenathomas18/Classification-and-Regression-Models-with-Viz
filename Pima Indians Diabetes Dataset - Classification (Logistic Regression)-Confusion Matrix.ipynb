{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pima-indians-diabetes.csv',na_values=0, names =['NooftimesPreg', 'Plasma','Diastolic', 'Triceps' , 'Insulin','BMI','Diabetes','Age','Class' ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NooftimesPreg</th>\n",
       "      <th>Plasma</th>\n",
       "      <th>Diastolic</th>\n",
       "      <th>Triceps</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>10.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>764</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765</td>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NooftimesPreg  Plasma  Diastolic  Triceps  Insulin   BMI  Diabetes  Age  \\\n",
       "0              6.0   148.0       72.0     35.0      NaN  33.6     0.627   50   \n",
       "1              1.0    85.0       66.0     29.0      NaN  26.6     0.351   31   \n",
       "2              8.0   183.0       64.0      NaN      NaN  23.3     0.672   32   \n",
       "3              1.0    89.0       66.0     23.0     94.0  28.1     0.167   21   \n",
       "4              NaN   137.0       40.0     35.0    168.0  43.1     2.288   33   \n",
       "..             ...     ...        ...      ...      ...   ...       ...  ...   \n",
       "763           10.0   101.0       76.0     48.0    180.0  32.9     0.171   63   \n",
       "764            2.0   122.0       70.0     27.0      NaN  36.8     0.340   27   \n",
       "765            5.0   121.0       72.0     23.0    112.0  26.2     0.245   30   \n",
       "766            1.0   126.0       60.0      NaN      NaN  30.1     0.349   47   \n",
       "767            1.0    93.0       70.0     31.0      NaN  30.4     0.315   23   \n",
       "\n",
       "     Class  \n",
       "0      1.0  \n",
       "1      NaN  \n",
       "2      1.0  \n",
       "3      NaN  \n",
       "4      1.0  \n",
       "..     ...  \n",
       "763    NaN  \n",
       "764    NaN  \n",
       "765    NaN  \n",
       "766    1.0  \n",
       "767    NaN  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "df.Class.unique()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NooftimesPreg</th>\n",
       "      <th>Plasma</th>\n",
       "      <th>Diastolic</th>\n",
       "      <th>Triceps</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NooftimesPreg  Plasma  Diastolic  Triceps  Insulin   BMI  Diabetes  Age  \\\n",
       "0            6.0   148.0       72.0     35.0      NaN  33.6     0.627   50   \n",
       "\n",
       "   Class  \n",
       "0    1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Handling Outliers for all numeric columns\n",
    "#Numeric columns - No of times Pregnant , Plasma , Diastolic ,Triceps, Insulin, Diabetes, Age\n",
    "#To remove Outlier we can use 1.5 IQR Rule\n",
    "def outlierDetection(datacolumn):\n",
    "    #Sort the data in ascending order\n",
    "    #GET Q1 and Q3\n",
    "    Q1,Q3 = np.percentile(datacolumn, [25,75])\n",
    "    \n",
    "    #Calc IQR\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    #Calc LowerRange\n",
    "    lr = Q1 - (1.5 * IQR)\n",
    "    #Calc Upper Range\n",
    "    ur = Q3 + (1.5 * IQR)\n",
    "    #return 1,2\n",
    "    return lr,ur\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col 'NooftimesPreg' \n",
      "Col 'Plasma' \n",
      "Col 'Diastolic' \n",
      "Col 'Triceps' \n",
      "Col 'Insulin' \n",
      "Col 'BMI' \n",
      "Col 'Diabetes' \n",
      "Outlier Detected for 'Diabetes' \n",
      "Col 'Age' \n",
      "Outlier Detected for 'Age' \n"
     ]
    }
   ],
   "source": [
    "#Numeric columns - TV, radio,newspaper, sales  \n",
    "df.columns.to_list()\n",
    "#Consider only numeric columns \n",
    "\n",
    "num_list = ['NooftimesPreg','Plasma','Diastolic','Triceps','Insulin','BMI','Diabetes','Age']\n",
    "for col in num_list:\n",
    "    print (\"Col %r \" % col)\n",
    "    lowerRange,upperRange = outlierDetection(df[col])\n",
    "    outlier_upper = df[col] > upperRange \n",
    "    outlier_lower = df[col] < lowerRange\n",
    "    if outlier_upper.any() or outlier_lower.any():\n",
    "        print (\"Outlier Detected for %r \" % col)\n",
    "    df.drop(df[(df[col] > upperRange) | (df[col] < lowerRange)].index , inplace=True)\n",
    "df.set_index(np.arange(0,len(df)) , inplace=True)\n",
    "#Hence as confirmed this dataset -there are no  outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NooftimesPreg</th>\n",
       "      <th>Plasma</th>\n",
       "      <th>Diastolic</th>\n",
       "      <th>Triceps</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>10.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>726</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>727</td>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NooftimesPreg  Plasma  Diastolic  Triceps  Insulin   BMI  Diabetes  Age  \\\n",
       "0              6.0   148.0       72.0     35.0      NaN  33.6     0.627   50   \n",
       "1              1.0    85.0       66.0     29.0      NaN  26.6     0.351   31   \n",
       "2              8.0   183.0       64.0      NaN      NaN  23.3     0.672   32   \n",
       "3              1.0    89.0       66.0     23.0     94.0  28.1     0.167   21   \n",
       "4              5.0   116.0       74.0      NaN      NaN  25.6     0.201   30   \n",
       "..             ...     ...        ...      ...      ...   ...       ...  ...   \n",
       "725           10.0   101.0       76.0     48.0    180.0  32.9     0.171   63   \n",
       "726            2.0   122.0       70.0     27.0      NaN  36.8     0.340   27   \n",
       "727            5.0   121.0       72.0     23.0    112.0  26.2     0.245   30   \n",
       "728            1.0   126.0       60.0      NaN      NaN  30.1     0.349   47   \n",
       "729            1.0    93.0       70.0     31.0      NaN  30.4     0.315   23   \n",
       "\n",
       "     Class  \n",
       "0      1.0  \n",
       "1      NaN  \n",
       "2      1.0  \n",
       "3      NaN  \n",
       "4      NaN  \n",
       "..     ...  \n",
       "725    NaN  \n",
       "726    NaN  \n",
       "727    NaN  \n",
       "728    1.0  \n",
       "729    NaN  \n",
       "\n",
       "[730 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  1.,  8.,  5.,  3., 10.,  2.,  4.,  7., nan,  9., 11., 13.,\n",
       "       15., 17., 12., 14.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.NooftimesPreg.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NooftimesPreg    104\n",
       "Plasma             5\n",
       "Diastolic         34\n",
       "Triceps          216\n",
       "Insulin          355\n",
       "BMI                9\n",
       "Diabetes           0\n",
       "Age                0\n",
       "Class            481\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values present in Plasma, Diastolic , Triceps, Insulin, BMI - cont numeric -replace with mean \n",
    "\n",
    "\n",
    "col_list = ['Plasma','Diastolic','Triceps','Insulin','BMI']\n",
    "for col in col_list:\n",
    "    df[col].fillna(round(df[col].mean(),1) , inplace=True)\n",
    "    \n",
    "df['NooftimesPreg'].fillna(round(df['NooftimesPreg'].median(),1) , inplace=True)\n",
    "#Missing values present in NooftimesPregnant -dicrete numeric -replace with median \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NooftimesPreg      0\n",
       "Plasma             0\n",
       "Diastolic          0\n",
       "Triceps            0\n",
       "Insulin            0\n",
       "BMI                0\n",
       "Diabetes           0\n",
       "Age                0\n",
       "Class            481\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping all features\n",
    "df\n",
    "#Check whether teh data is a balanced dataset or not\n",
    "\n",
    "df['Class'] = df['Class'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NooftimesPreg    0\n",
       "Plasma           0\n",
       "Diastolic        0\n",
       "Triceps          0\n",
       "Insulin          0\n",
       "BMI              0\n",
       "Diabetes         0\n",
       "Age              0\n",
       "Class            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    481\n",
       "1.0    249\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check whether teh data is a balanced dataset or not\n",
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is Unbalanced\n",
    "# Rules for Classification Usecase if you use SKLEARN for modelling\n",
    "# 1. Data must be complete\n",
    "# 2. Features must be strictly numeric. Labels can be numeric or non-numeric\n",
    "# 3. Data must be represented in the form of numpy array\n",
    "# 4. Features must be a 2d array\n",
    "# 5. Label must be  1d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, 8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seperate data as features and label\n",
    "features = df.iloc[:,[0,1,2,3,4,5,6,7]].values\n",
    "label = df.Class.values\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NooftimesPreg    0\n",
       "Plasma           0\n",
       "Diastolic        0\n",
       "Triceps          0\n",
       "Insulin          0\n",
       "BMI              0\n",
       "Diabetes         0\n",
       "Age              0\n",
       "Class            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0.7945205479452054 Train0.7722602739726028 RS2\n",
      "Test 0.7945205479452054 Train0.7671232876712328 RS3\n",
      "Test 0.7945205479452054 Train0.7688356164383562 RS4\n",
      "Test 0.7876712328767124 Train0.7705479452054794 RS7\n",
      "Test 0.7876712328767124 Train0.7722602739726028 RS9\n",
      "Test 0.7808219178082192 Train0.7773972602739726 RS14\n",
      "Test 0.7876712328767124 Train0.7842465753424658 RS16\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS20\n",
      "Test 0.7945205479452054 Train0.7722602739726028 RS22\n",
      "Test 0.821917808219178 Train0.7705479452054794 RS23\n",
      "Test 0.7945205479452054 Train0.7705479452054794 RS24\n",
      "Test 0.8287671232876712 Train0.7671232876712328 RS28\n",
      "Test 0.8013698630136986 Train0.7688356164383562 RS29\n",
      "Test 0.7945205479452054 Train0.7671232876712328 RS34\n",
      "Test 0.7808219178082192 Train0.7671232876712328 RS36\n",
      "Test 0.7876712328767124 Train0.7722602739726028 RS38\n",
      "Test 0.7808219178082192 Train0.7756849315068494 RS40\n",
      "Test 0.7876712328767124 Train0.7688356164383562 RS41\n",
      "Test 0.8493150684931506 Train0.7636986301369864 RS42\n",
      "Test 0.8013698630136986 Train0.7688356164383562 RS47\n",
      "Test 0.8561643835616438 Train0.7568493150684932 RS49\n",
      "Test 0.7876712328767124 Train0.7705479452054794 RS52\n",
      "Test 0.815068493150685 Train0.7688356164383562 RS53\n",
      "Test 0.773972602739726 Train0.7722602739726028 RS56\n",
      "Test 0.7808219178082192 Train0.7722602739726028 RS58\n",
      "Test 0.7945205479452054 Train0.7791095890410958 RS59\n",
      "Test 0.8013698630136986 Train0.7636986301369864 RS60\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS61\n",
      "Test 0.8013698630136986 Train0.7756849315068494 RS62\n",
      "Test 0.7876712328767124 Train0.773972602739726 RS64\n",
      "Test 0.8013698630136986 Train0.761986301369863 RS65\n",
      "Test 0.7945205479452054 Train0.7705479452054794 RS66\n",
      "Test 0.8082191780821918 Train0.7705479452054794 RS68\n",
      "Test 0.8287671232876712 Train0.7671232876712328 RS69\n",
      "Test 0.8082191780821918 Train0.7705479452054794 RS70\n",
      "Test 0.815068493150685 Train0.7671232876712328 RS72\n",
      "Test 0.8082191780821918 Train0.7705479452054794 RS76\n",
      "Test 0.8287671232876712 Train0.7654109589041096 RS78\n",
      "Test 0.821917808219178 Train0.7705479452054794 RS79\n",
      "Test 0.8082191780821918 Train0.7722602739726028 RS83\n",
      "Test 0.7945205479452054 Train0.7722602739726028 RS84\n",
      "Test 0.8082191780821918 Train0.7671232876712328 RS85\n",
      "Test 0.7876712328767124 Train0.7688356164383562 RS86\n",
      "Test 0.7808219178082192 Train0.7756849315068494 RS87\n",
      "Test 0.7945205479452054 Train0.7654109589041096 RS89\n",
      "Test 0.7876712328767124 Train0.773972602739726 RS90\n",
      "Test 0.7876712328767124 Train0.7671232876712328 RS92\n",
      "Test 0.8013698630136986 Train0.773972602739726 RS93\n",
      "Test 0.7876712328767124 Train0.773972602739726 RS95\n",
      "Test 0.7876712328767124 Train0.7756849315068494 RS96\n",
      "Test 0.7945205479452054 Train0.7722602739726028 RS99\n",
      "Test 0.815068493150685 Train0.7722602739726028 RS101\n",
      "Test 0.8356164383561644 Train0.7568493150684932 RS102\n",
      "Test 0.7808219178082192 Train0.7722602739726028 RS105\n",
      "Test 0.8082191780821918 Train0.7705479452054794 RS122\n",
      "Test 0.815068493150685 Train0.7688356164383562 RS126\n",
      "Test 0.8013698630136986 Train0.7688356164383562 RS130\n",
      "Test 0.7808219178082192 Train0.773972602739726 RS132\n",
      "Test 0.7808219178082192 Train0.7705479452054794 RS134\n",
      "Test 0.7945205479452054 Train0.7756849315068494 RS136\n",
      "Test 0.8013698630136986 Train0.7722602739726028 RS140\n",
      "Test 0.8424657534246576 Train0.7636986301369864 RS141\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS144\n",
      "Test 0.8013698630136986 Train0.773972602739726 RS147\n",
      "Test 0.7808219178082192 Train0.773972602739726 RS148\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS150\n",
      "Test 0.7876712328767124 Train0.7705479452054794 RS151\n",
      "Test 0.8013698630136986 Train0.7688356164383562 RS153\n",
      "Test 0.7945205479452054 Train0.7688356164383562 RS155\n",
      "Test 0.8082191780821918 Train0.7654109589041096 RS157\n",
      "Test 0.8013698630136986 Train0.7705479452054794 RS161\n",
      "Test 0.7945205479452054 Train0.7654109589041096 RS163\n",
      "Test 0.7876712328767124 Train0.7636986301369864 RS166\n",
      "Test 0.8013698630136986 Train0.773972602739726 RS170\n",
      "Test 0.8013698630136986 Train0.7756849315068494 RS171\n",
      "Test 0.8013698630136986 Train0.7688356164383562 RS172\n",
      "Test 0.7876712328767124 Train0.7773972602739726 RS184\n",
      "Test 0.773972602739726 Train0.7722602739726028 RS186\n",
      "Test 0.815068493150685 Train0.7688356164383562 RS187\n",
      "Test 0.815068493150685 Train0.7688356164383562 RS191\n",
      "Test 0.7876712328767124 Train0.7688356164383562 RS192\n",
      "Test 0.8013698630136986 Train0.7756849315068494 RS193\n",
      "Test 0.7876712328767124 Train0.7688356164383562 RS197\n",
      "Test 0.815068493150685 Train0.7705479452054794 RS199\n",
      "Test 0.7876712328767124 Train0.7842465753424658 RS200\n",
      "Test 0.821917808219178 Train0.7602739726027398 RS203\n",
      "Test 0.7808219178082192 Train0.7756849315068494 RS213\n",
      "Test 0.7945205479452054 Train0.7602739726027398 RS215\n",
      "Test 0.7876712328767124 Train0.7773972602739726 RS217\n",
      "Test 0.821917808219178 Train0.7654109589041096 RS221\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS230\n",
      "Test 0.8013698630136986 Train0.7773972602739726 RS231\n",
      "Test 0.7945205479452054 Train0.7791095890410958 RS232\n",
      "Test 0.7808219178082192 Train0.7722602739726028 RS235\n",
      "Test 0.7876712328767124 Train0.7791095890410958 RS240\n",
      "Test 0.7808219178082192 Train0.7756849315068494 RS242\n",
      "Test 0.7876712328767124 Train0.7722602739726028 RS243\n",
      "Test 0.7876712328767124 Train0.7773972602739726 RS244\n",
      "Test 0.815068493150685 Train0.7602739726027398 RS246\n",
      "Test 0.8013698630136986 Train0.7671232876712328 RS248\n",
      "Test 0.8013698630136986 Train0.7791095890410958 RS249\n",
      "Test 0.8082191780821918 Train0.7722602739726028 RS250\n",
      "Test 0.7945205479452054 Train0.7756849315068494 RS255\n",
      "Test 0.8082191780821918 Train0.7705479452054794 RS256\n",
      "Test 0.8013698630136986 Train0.7722602739726028 RS260\n",
      "Test 0.773972602739726 Train0.7722602739726028 RS261\n",
      "Test 0.815068493150685 Train0.7688356164383562 RS264\n",
      "Test 0.815068493150685 Train0.7688356164383562 RS267\n",
      "Test 0.773972602739726 Train0.7671232876712328 RS269\n",
      "Test 0.7945205479452054 Train0.7808219178082192 RS271\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS273\n",
      "Test 0.815068493150685 Train0.7705479452054794 RS274\n",
      "Test 0.8082191780821918 Train0.7773972602739726 RS276\n",
      "Test 0.7945205479452054 Train0.7722602739726028 RS277\n",
      "Test 0.7876712328767124 Train0.773972602739726 RS278\n",
      "Test 0.7876712328767124 Train0.7756849315068494 RS282\n",
      "Test 0.7876712328767124 Train0.7705479452054794 RS285\n",
      "Test 0.8013698630136986 Train0.7773972602739726 RS287\n",
      "Test 0.7808219178082192 Train0.7654109589041096 RS288\n",
      "Test 0.7876712328767124 Train0.7756849315068494 RS289\n",
      "Test 0.815068493150685 Train0.7705479452054794 RS290\n",
      "Test 0.7945205479452054 Train0.7688356164383562 RS291\n",
      "Test 0.7945205479452054 Train0.7671232876712328 RS293\n",
      "Test 0.821917808219178 Train0.7722602739726028 RS296\n",
      "Test 0.7876712328767124 Train0.773972602739726 RS297\n",
      "Test 0.8013698630136986 Train0.7756849315068494 RS298\n",
      "Test 0.8013698630136986 Train0.7688356164383562 RS300\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS301\n",
      "Test 0.7808219178082192 Train0.7722602739726028 RS308\n",
      "Test 0.7945205479452054 Train0.7722602739726028 RS311\n",
      "Test 0.773972602739726 Train0.7671232876712328 RS312\n",
      "Test 0.7876712328767124 Train0.7773972602739726 RS314\n",
      "Test 0.7808219178082192 Train0.7773972602739726 RS316\n",
      "Test 0.8013698630136986 Train0.7756849315068494 RS317\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS318\n",
      "Test 0.815068493150685 Train0.7654109589041096 RS319\n",
      "Test 0.7876712328767124 Train0.7722602739726028 RS321\n",
      "Test 0.7945205479452054 Train0.7722602739726028 RS322\n",
      "Test 0.773972602739726 Train0.7722602739726028 RS323\n",
      "Test 0.7808219178082192 Train0.773972602739726 RS324\n",
      "Test 0.8013698630136986 Train0.7688356164383562 RS327\n",
      "Test 0.773972602739726 Train0.7722602739726028 RS328\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS330\n",
      "Test 0.815068493150685 Train0.761986301369863 RS332\n",
      "Test 0.7808219178082192 Train0.7773972602739726 RS336\n",
      "Test 0.7808219178082192 Train0.7722602739726028 RS337\n",
      "Test 0.815068493150685 Train0.7688356164383562 RS338\n",
      "Test 0.8356164383561644 Train0.7585616438356164 RS342\n",
      "Test 0.8424657534246576 Train0.7585616438356164 RS345\n",
      "Test 0.8356164383561644 Train0.7585616438356164 RS346\n",
      "Test 0.8013698630136986 Train0.7688356164383562 RS350\n",
      "Test 0.8013698630136986 Train0.7722602739726028 RS352\n",
      "Test 0.8013698630136986 Train0.761986301369863 RS358\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0.7876712328767124 Train0.7773972602739726 RS364\n",
      "Test 0.7876712328767124 Train0.7671232876712328 RS370\n",
      "Test 0.7876712328767124 Train0.7688356164383562 RS373\n",
      "Test 0.7808219178082192 Train0.7773972602739726 RS375\n",
      "Test 0.8287671232876712 Train0.7688356164383562 RS376\n",
      "Test 0.8082191780821918 Train0.773972602739726 RS377\n",
      "Test 0.773972602739726 Train0.7671232876712328 RS381\n",
      "Test 0.821917808219178 Train0.7688356164383562 RS382\n",
      "Test 0.815068493150685 Train0.7722602739726028 RS384\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS385\n",
      "Test 0.7945205479452054 Train0.7756849315068494 RS386\n",
      "Test 0.7876712328767124 Train0.7773972602739726 RS387\n",
      "Test 0.7945205479452054 Train0.761986301369863 RS388\n",
      "Test 0.7876712328767124 Train0.7773972602739726 RS393\n",
      "Test 0.773972602739726 Train0.7722602739726028 RS397\n",
      "Test 0.815068493150685 Train0.7671232876712328 RS403\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS406\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS409\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS411\n",
      "Test 0.7945205479452054 Train0.7791095890410958 RS412\n",
      "Test 0.8082191780821918 Train0.7705479452054794 RS413\n",
      "Test 0.7808219178082192 Train0.7722602739726028 RS415\n",
      "Test 0.7876712328767124 Train0.7773972602739726 RS421\n",
      "Test 0.773972602739726 Train0.7705479452054794 RS424\n",
      "Test 0.7808219178082192 Train0.773972602739726 RS429\n",
      "Test 0.7876712328767124 Train0.7808219178082192 RS433\n",
      "Test 0.815068493150685 Train0.7671232876712328 RS436\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS437\n",
      "Test 0.821917808219178 Train0.7654109589041096 RS439\n",
      "Test 0.8287671232876712 Train0.7688356164383562 RS444\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS448\n",
      "Test 0.8082191780821918 Train0.7756849315068494 RS449\n",
      "Test 0.8013698630136986 Train0.7705479452054794 RS450\n",
      "Test 0.7808219178082192 Train0.7722602739726028 RS451\n",
      "Test 0.8082191780821918 Train0.7722602739726028 RS455\n",
      "Test 0.8287671232876712 Train0.7756849315068494 RS463\n",
      "Test 0.7876712328767124 Train0.7722602739726028 RS467\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS469\n",
      "Test 0.7945205479452054 Train0.7722602739726028 RS470\n",
      "Test 0.815068493150685 Train0.7705479452054794 RS483\n",
      "Test 0.8013698630136986 Train0.7671232876712328 RS485\n",
      "Test 0.8013698630136986 Train0.7705479452054794 RS487\n",
      "Test 0.7945205479452054 Train0.7705479452054794 RS489\n",
      "Test 0.7876712328767124 Train0.773972602739726 RS490\n",
      "Test 0.773972602739726 Train0.7722602739726028 RS492\n",
      "Test 0.7876712328767124 Train0.7756849315068494 RS494\n",
      "Test 0.773972602739726 Train0.7671232876712328 RS496\n",
      "Test 0.7876712328767124 Train0.7791095890410958 RS499\n",
      "Test 0.7945205479452054 Train0.7705479452054794 RS504\n",
      "Test 0.8082191780821918 Train0.773972602739726 RS510\n",
      "Test 0.7876712328767124 Train0.7722602739726028 RS511\n",
      "Test 0.7945205479452054 Train0.761986301369863 RS513\n",
      "Test 0.7876712328767124 Train0.7791095890410958 RS516\n",
      "Test 0.8082191780821918 Train0.7773972602739726 RS522\n",
      "Test 0.7808219178082192 Train0.7705479452054794 RS523\n",
      "Test 0.815068493150685 Train0.7722602739726028 RS527\n",
      "Test 0.7808219178082192 Train0.773972602739726 RS531\n",
      "Test 0.7945205479452054 Train0.7636986301369864 RS532\n",
      "Test 0.8287671232876712 Train0.7654109589041096 RS533\n",
      "Test 0.7808219178082192 Train0.7756849315068494 RS535\n",
      "Test 0.7876712328767124 Train0.7756849315068494 RS536\n",
      "Test 0.7945205479452054 Train0.7688356164383562 RS539\n",
      "Test 0.7945205479452054 Train0.7705479452054794 RS541\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS542\n",
      "Test 0.815068493150685 Train0.7636986301369864 RS543\n",
      "Test 0.8082191780821918 Train0.7654109589041096 RS545\n",
      "Test 0.8082191780821918 Train0.7654109589041096 RS546\n",
      "Test 0.7808219178082192 Train0.7773972602739726 RS548\n",
      "Test 0.821917808219178 Train0.7688356164383562 RS551\n",
      "Test 0.8493150684931506 Train0.7585616438356164 RS553\n",
      "Test 0.8082191780821918 Train0.7756849315068494 RS554\n",
      "Test 0.7876712328767124 Train0.7773972602739726 RS555\n",
      "Test 0.7808219178082192 Train0.7756849315068494 RS556\n",
      "Test 0.8356164383561644 Train0.7654109589041096 RS557\n",
      "Test 0.7945205479452054 Train0.7636986301369864 RS558\n",
      "Test 0.7876712328767124 Train0.7791095890410958 RS561\n",
      "Test 0.773972602739726 Train0.7705479452054794 RS563\n",
      "Test 0.7876712328767124 Train0.7688356164383562 RS566\n",
      "Test 0.815068493150685 Train0.7688356164383562 RS567\n",
      "Test 0.8082191780821918 Train0.773972602739726 RS568\n",
      "Test 0.8082191780821918 Train0.7636986301369864 RS570\n",
      "Test 0.8287671232876712 Train0.7705479452054794 RS572\n",
      "Test 0.7876712328767124 Train0.7756849315068494 RS576\n",
      "Test 0.8287671232876712 Train0.7654109589041096 RS577\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS578\n",
      "Test 0.7876712328767124 Train0.7791095890410958 RS579\n",
      "Test 0.7876712328767124 Train0.7756849315068494 RS583\n",
      "Test 0.773972602739726 Train0.7705479452054794 RS584\n",
      "Test 0.8424657534246576 Train0.761986301369863 RS585\n",
      "Test 0.7945205479452054 Train0.7773972602739726 RS586\n",
      "Test 0.8082191780821918 Train0.7654109589041096 RS588\n",
      "Test 0.8013698630136986 Train0.773972602739726 RS590\n",
      "Test 0.7945205479452054 Train0.7688356164383562 RS591\n",
      "Test 0.7808219178082192 Train0.7756849315068494 RS595\n",
      "Test 0.8013698630136986 Train0.7756849315068494 RS596\n",
      "Test 0.7945205479452054 Train0.761986301369863 RS600\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS602\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS603\n",
      "Test 0.8013698630136986 Train0.773972602739726 RS604\n",
      "Test 0.8082191780821918 Train0.7654109589041096 RS605\n",
      "Test 0.773972602739726 Train0.7722602739726028 RS606\n",
      "Test 0.8082191780821918 Train0.7722602739726028 RS607\n",
      "Test 0.7945205479452054 Train0.7722602739726028 RS608\n",
      "Test 0.8013698630136986 Train0.7722602739726028 RS609\n",
      "Test 0.7808219178082192 Train0.7773972602739726 RS610\n",
      "Test 0.815068493150685 Train0.7688356164383562 RS611\n",
      "Test 0.7945205479452054 Train0.773972602739726 RS614\n",
      "Test 0.7945205479452054 Train0.7756849315068494 RS615\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS619\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS620\n",
      "Test 0.8082191780821918 Train0.7671232876712328 RS622\n",
      "Test 0.7808219178082192 Train0.773972602739726 RS624\n",
      "Test 0.815068493150685 Train0.773972602739726 RS628\n",
      "Test 0.8082191780821918 Train0.7636986301369864 RS630\n",
      "Test 0.773972602739726 Train0.7705479452054794 RS633\n",
      "Test 0.8013698630136986 Train0.7722602739726028 RS634\n",
      "Test 0.7945205479452054 Train0.7688356164383562 RS636\n",
      "Test 0.7876712328767124 Train0.7722602739726028 RS637\n",
      "Test 0.7945205479452054 Train0.7722602739726028 RS638\n",
      "Test 0.7876712328767124 Train0.773972602739726 RS644\n",
      "Test 0.7876712328767124 Train0.7722602739726028 RS645\n",
      "Test 0.8013698630136986 Train0.7654109589041096 RS647\n",
      "Test 0.8013698630136986 Train0.761986301369863 RS651\n",
      "Test 0.7808219178082192 Train0.7722602739726028 RS653\n",
      "Test 0.7945205479452054 Train0.7688356164383562 RS654\n",
      "Test 0.7876712328767124 Train0.7756849315068494 RS655\n",
      "Test 0.7808219178082192 Train0.773972602739726 RS660\n",
      "Test 0.773972602739726 Train0.7705479452054794 RS661\n",
      "Test 0.815068493150685 Train0.7688356164383562 RS664\n",
      "Test 0.8013698630136986 Train0.7756849315068494 RS665\n",
      "Test 0.815068493150685 Train0.7636986301369864 RS666\n",
      "Test 0.7808219178082192 Train0.7722602739726028 RS668\n",
      "Test 0.7808219178082192 Train0.7791095890410958 RS670\n",
      "Test 0.8561643835616438 Train0.7602739726027398 RS672\n",
      "Test 0.821917808219178 Train0.761986301369863 RS673\n",
      "Test 0.7808219178082192 Train0.7722602739726028 RS678\n",
      "Test 0.8561643835616438 Train0.7534246575342466 RS680\n",
      "Test 0.7945205479452054 Train0.7756849315068494 RS683\n",
      "Test 0.7945205479452054 Train0.7756849315068494 RS686\n",
      "Test 0.8013698630136986 Train0.773972602739726 RS687\n",
      "Test 0.7808219178082192 Train0.7773972602739726 RS689\n",
      "Test 0.821917808219178 Train0.7688356164383562 RS690\n",
      "Test 0.8013698630136986 Train0.7722602739726028 RS705\n",
      "Test 0.773972602739726 Train0.7722602739726028 RS707\n",
      "Test 0.7876712328767124 Train0.7773972602739726 RS708\n",
      "Test 0.8013698630136986 Train0.7671232876712328 RS709\n",
      "Test 0.8767123287671232 Train0.7517123287671232 RS715\n",
      "Test 0.7876712328767124 Train0.773972602739726 RS719\n",
      "Test 0.7808219178082192 Train0.7654109589041096 RS722\n",
      "Test 0.7945205479452054 Train0.7688356164383562 RS724\n",
      "Test 0.7945205479452054 Train0.7705479452054794 RS725\n",
      "Test 0.8013698630136986 Train0.773972602739726 RS727\n",
      "The random state for the max test score  of 0.8767123287671232 is 715  \n",
      "Since test score is greater than train score this model is good\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def determine_RS(features, label):\n",
    "    max_val = 0\n",
    "    random_state = 0\n",
    "    hit = 0\n",
    "    for i in range(1,731):\n",
    "        X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                    label,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=i)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        train_s = model.score(X_train,y_train)\n",
    "        test_s = model.score(X_test,y_test)\n",
    "\n",
    "        if test_s > train_s:\n",
    "            hit = 1\n",
    "            if test_s > max_val:\n",
    "                max_val = test_s\n",
    "                random_state = i\n",
    "            print(\"Test {} Train{} RS{}\".format(test_s,train_s,i))\n",
    "    return max_val , random_state, hit\n",
    "\n",
    "\n",
    "max_test_score ,random_state, hit = determine_RS(features, label)\n",
    "\n",
    "print (\"The random state for the max test score  of %r is %r  \" % (max_test_score, random_state))\n",
    "if hit:\n",
    "    print (\"Since test score is greater than train score this model is good\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train score 0.7517123287671232 \n",
      " Test score 0.8767123287671232 \n"
     ]
    }
   ],
   "source": [
    "# Now  Create Train Test Splits with the best random state\n",
    "#Random state = 715\n",
    "def apply_best_RS(random_state, features):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                     label,\n",
    "                                                     test_size=0.2,\n",
    "                                                     random_state = random_state)\n",
    "    lrModel = LogisticRegression()\n",
    "\n",
    "    lrModel.fit(X_train,y_train)\n",
    "\n",
    "    # We use accuracy check as a mechanism to check the quality of the model\n",
    "    print ( \" Train score %r \" % lrModel.score(X_train,y_train))\n",
    "    # To ensure our model quality is GOOD, ensure your model performs well with Unknown data\n",
    "    print ( \" Test score %r \" %lrModel.score(X_test,y_test))\n",
    "    return lrModel\n",
    "lrModel = apply_best_RS(random_state, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the Quality of Model\n",
    "# 1. Ensure your model is a generalized model\n",
    "# 2. If dataset is balanced, check the accuracy score and compare the same with the CL value\n",
    "#.   If dataset is unbalanced, (Suggestion by Prashant Nair)\n",
    "#.        1. Check the Non-tolerable scenario and get the AREA OF FOCUS.\n",
    "#         2. Based on AREA OF FOCUS, get relevant Precision and Recall Scores\n",
    "#.        3. Take AVG and compare the same with CL (65 %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ensure your model is a generalized model\n",
    "#.   Since the dataset is unbalanced,\n",
    "#.        0. Get the confusion Matrix and All metric values\n",
    "#.        1. Check the Non-tolerable scenario and get the AREA OF FOCUS.\n",
    "#         2. Based on AREA OF FOCUS, get relevant Precision and Recall Scores\n",
    "#.        3. Take AVG and compare the same with CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-tolerable: Customer who is intending to purchase shouldnt be listed in non-purchased\n",
    "\n",
    "#Diabetic detected non diabetic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[428,  53],\n",
       "       [110, 139]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.        0. Get the confusion Matrix and All metric values\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(label, lrModel.predict(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.89      0.84       481\n",
      "         1.0       0.72      0.56      0.63       249\n",
      "\n",
      "    accuracy                           0.78       730\n",
      "   macro avg       0.76      0.72      0.74       730\n",
      "weighted avg       0.77      0.78      0.77       730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label, lrModel.predict(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#115 - 3rd Quadrant will be our Area of Focus\n",
    "#ie. average of PRecision of Non Diabetes and Recall of Diabetes = avg (0.72, 0.89)\n",
    "AreaOfFocus=0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confidence Level = 1 - SL\n",
    "CL = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept\n"
     ]
    }
   ],
   "source": [
    "#Validate if average of precision and recall is greater than CL for unbalanced support in order to accept model\n",
    "if (AreaOfFocus > CL):\n",
    "    print(\"Accept\")\n",
    "else:\n",
    "    print(\"Reject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
